{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Linear Regression\n",
    "- **Author:** satej soman ([satej@berkeley.edu](mailto:satej@berkeley.edu))\n",
    "- **Date:** Jan 22, 2025\n",
    "- **Course:** INFO 251: Applied Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "\n",
    "* Become familiar with statistical packages\n",
    "* Implement the OLS normal equations from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback:\n",
    "\n",
    "After the lab, please provide feedback via [this anonymous form](https://forms.gle/wNDEodLsHDJN8DPJ9). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. setting up your environment\n",
    "\n",
    "In whichever computing environment you prefer (Anaconda, Google Colab, etc.) install the packages below and ensure you are able to import them without issues. \n",
    "\n",
    "Ask the TAs for assistance or come to office hours if you have issues with this step or any of the steps in Lab 0 (the prerequisite lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful imports!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# hints to the notebook renderer about how matplotlib plots should be displayed\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulating randomness\n",
    "\n",
    "### 1.1. random number generators\n",
    "\n",
    "In machine learning, it's useful to use some math to model processes that are probabilistic, or stochastic, or non-deterministic. Computers, on the other hand, generally do not do well with non-determinism, so we simulate sequences of random events with _pseudo-random number generators_ (PRNGs) - functions that to an outside observer, return sequences of numbers that appear as if they are random. PRNGs can be used to simulate sequences of numbers that appear to follow specific statistical distributions. The [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html) and [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) packages implement several PRNGs that allow us to simulate sampling from different distributions. \n",
    "\n",
    "Below are some examples of using `numpy.random` to:\n",
    "\n",
    "- generate one single random number uniformly distributed over the range $[0, 1)$\n",
    "- generate an array of 5 numbers according to a unit normal distribution\n",
    "- generate an array of 20 integers uniformly over the range $[0, 100)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces a single random number uniformly distributed over the range $[0, 1)$\n",
    "print(np.random.random())\n",
    "\n",
    "# generates 5 random numbers distributed according to a zero-mean, unit-variance normal distribution\n",
    "print(np.random.standard_normal(5))\n",
    "\n",
    "# generates 20 random integers in the range 0 to 100\n",
    "print(np.random.randint(low=0, high=100, size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. setting PRNG seeds\n",
    "\n",
    "The exact same code presented above is replicated below. Run this cell. Is the output the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces a single random number uniformly distributed over the range $[0, 1)$\n",
    "print(np.random.random())\n",
    "\n",
    "# generates 5 random numbers distributed according to a zero-mean, unit-variance normal distribution\n",
    "print(np.random.standard_normal(5))\n",
    "\n",
    "# generates 20 random integers in the range 0 to 100\n",
    "print(np.random.randint(low=0, high=100, size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you were very, very, very lucky, you will see different numbers this time around. This is what you want to see from a pseudo-random number generator! Compare the outputs of both code cells with those of one or two labmates around you.\n",
    "\n",
    "However, to make your results reproducible by others, you should always set the _seed_, or internal state of the PRNG function. Once a seed is set, the random numbers generated will follow the same pattern. With `numpy` this is done by calling the `np.random.seed` function and passing in a number. \n",
    "\n",
    "Below, set the random seed to `251`, and copy the lines of code from the first code cell below that. After that code, set the seed to `251` again, and copy the code to generate random numbers one more time. Run the code cell. What do you see? Compare the outputs of this code cell with those of one or two labmates around you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE\n",
    "\n",
    "# set the seed to 251\n",
    "\n",
    "\n",
    "# run the three calls to random number generators\n",
    "\n",
    "\n",
    "# - \n",
    "\n",
    "# set the seed to 251 again\n",
    "\n",
    "\n",
    "# run the three calls to random number generators again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estimating parameters of a distribution\n",
    "\n",
    "Just before lecture yesterday, Josh spent a couple hours flipping a coin 10,000 times. He saved his results in `coin_flips.txt`, where the $n$-th row is `1` if he flipped a heads on attempt $n$, and `0` if he flipped a tails. We'd like to know if the coin is fair.\n",
    "\n",
    "\n",
    "\n",
    "- What probability distribution describes the outcome of a single coin flip? What distribution does the entire dataset follow?\n",
    "- What is a simple quantity to calculate in order to check if the coin he flipped is fair? What statistical test would you use to quantify your uncertainty about your answer?\n",
    "\n",
    "- Read in the data (see: [`numpy.loadtxt`](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html)). For $N = 100, 200, 300, ..., 10,000$, implement your simple check on the first $N$ rows of data. Plot the results of the check as a function of $N$.\n",
    "\n",
    "- Is the coin fair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OLS normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Let's work through Exercise 2.2 of the Stats Refresher (optional)\n",
    "\n",
    "Recall the formulae for the OLS estimators for regressing a scalar $y$ on a scalar $x$ (bars over quantities denote sample averages):\n",
    "\n",
    "\n",
    "$$\\widehat{\\beta}_1 = \\frac{\\sum_i (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_i (x_i - \\overline{x})^2} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\widehat{\\beta}_0 = \\overline{y} - \\widehat{\\beta}_1 \\overline{x}$$\n",
    "\n",
    "Show that the expressions above for $\\widehat{\\beta}_0$ and $\\widehat{\\beta}_1$ are the result of minimizing the mean square error loss $L$ (defined below) over $n$ data points $\\left\\{x_i, y_i\\right\\}$ with respect to the parameters $\\beta_0$ and $\\beta_1$.\n",
    "\n",
    "$$ L = \\frac{1}{n}\\sum_i \\left( y_i - \\beta_0 - \\beta_1 x_i\\right)^2 $$\n",
    "\n",
    "\n",
    "<span style=\"color:orange\">suggestion:</span> if this takes you more than 10 minutes, move on to the rest of the lab and come back to it on your own time, or in office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. implementing OLS with `numpy`\n",
    "\n",
    "#### 3.2.1. synthetic data\n",
    "First, generate some data where we know the \"true\" values of the OLS coefficients.\n",
    "- Set the `numpy.random` seed to 0, so you can compare your work with that of your labmates.\n",
    "- Create a vector $\\mathbf{x} = [x_1, x_2, \\cdots, x_{1000}]$ of 1000 random numbers uniformly distributed between 0 and 100.\n",
    "- Create a vector $\\mathbf{e}$ of 1000 random numbers drawn from a normal distribution with a mean of zero and a _**variance**_ of 25.\n",
    "- Create a vector $\\mathbf{y}$ where $y_i = x_i/5 + 7 + e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. scalar equations \n",
    "\n",
    "Using the scalar formulae above and the synthetic data you generated, calculate $\\widehat{\\beta}_0$ and $\\widehat{\\beta}_1$ for regressing $\\mathbf{y}$ on $\\mathbf{x}$ and an intercept. What should you expect the answers to be? How do they compare?\n",
    "\n",
    "Create a scatter plot of the data, and plot the line of best fit $\\widehat{y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot x$ on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. matrix equations\n",
    "\n",
    "Recall that the estimate of the parameter vector $\\beta$ is also given by $\\widehat{\\beta} = (X^\\prime X)^{-1}(X^\\prime \\mathbf{y})$, where $X$ is the _design matrix_, and $X^\\prime$ denotes matrix transposition. \n",
    "\n",
    "- If we want to implement regression of $\\mathbf{y}$ on $\\mathbf{x}$ and an intercept this way, what should our design matrix be?\n",
    "- Create the design matrix with `numpy`. \n",
    "- Implement the matrix-algebra expression for OLS given above using `numpy` operations and compare your results to the scalar version and the \"true\" values. Hints:\n",
    "    - A multidimensional `numpy` array `X` can be transposed with the syntax `X.T`.\n",
    "    - For `numpy` arrays `a` and `b`, `a * b` will multiply each element of `a` with the corresponding element in `b`. Use `a @ b` for dot products and matrix-vector products.\n",
    "    - Use `np.linalg.inv` to invert matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OLS with `pandas` and `statsmodels` (optional - preview of next week's lab)\n",
    "\n",
    "### 4.1. `statsmodels` on our synthetic data\n",
    "\n",
    "We are rarely going to implement OLS from scratch like we just did. There are many off-the-shelf options for performing OLS in scientific/numeric/statistical computing packages (cf. [`np.linalg.lstsq`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html), [`scipy.stats.linregress`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html))\n",
    "\n",
    "For this exercise and the next lab, we will be using the OLS implementation found in `statsmodels`, imported at the top of this notebook as `sm`. \n",
    "\n",
    "To see how `statsmodels` compares to our implementations, use `sm.OLS` to run a regression on our synthetic dataset by running the code cell below. Are the coefficients the same?\n",
    "What information does the summary give you that our implementations did not? Is there information that hints at what we did differently with `sm`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE\n",
    "\n",
    "# specify a regression of y on x\n",
    "model = sm.OLS(y, x) \n",
    "# fit the model\n",
    "results = model.fit() \n",
    "# print coefficients\n",
    "print(f\"coefficients estimated by statsmodels: {results.params}\")\n",
    "print()\n",
    "print(\"summary:\")\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are not the same! We don't even have the same number of parameters! \n",
    "\n",
    "This is because we didn't specify a constant term (or intercept) in our regression. The warning about RÂ² says the same thing, and in the table of results, there isn't a row for the intercept. We can fix this by calling `sm.add_constant` on our regressors, which creates the design matrix properly. Run the code below and take note of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model with a constant\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "# fit the model\n",
    "results = model.fit() \n",
    "# print coefficients\n",
    "print(f\"params estimated by statsmodels: {results.params}\")\n",
    "print()\n",
    "print(\"Summary:\")\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. mind the gap - `statsmodels` on real data\n",
    "\n",
    "Let's run a regression on real data from the [Gapminder dataset](https://www.gapminder.org/data/), which collates development statistics for countries around the world. The file `gapminder.csv` contains a subset of the development metrics in the dataset. \n",
    "\n",
    "- Use `pandas` to read the dataset into a variable called `data`.\n",
    "- Print the name of each of the columns in the dataset.\n",
    "- Use the `DataFrame`'s `.dropna()` function to drop any missing values.\n",
    "- Filter the data to only include entries from the year 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress life expectancy (`life_exp`) on per-capita GDP (`gdp_cap`) and a constant. Assuming you read the data into a variable called `data`, you can extract the data for a column with a given `column_name` by calling `data[column_name]`. \n",
    "\n",
    "How well does this regression explain variation in life expectancy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're coming from a statistical programming language like R, you can also specify your regressions using formulae, which automatically include constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "smf.ols(formula=\"life_exp ~ gdp_cap\", data = data).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. (optional) OLS consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your `numpy` random seed back to 0. Do the following 1000 times:\n",
    "\n",
    "- Regenerate your synthetic data.\n",
    "- Calculate $\\widehat{\\beta}_1$ for that version of the synthetic data, and store it.\n",
    "\n",
    "Do not set the seed back to 0 after each iteration of the loop. This will ensure you have slightly different data on each iteration, but drawn from the same distribution.\n",
    "\n",
    "Plot a histogram of the estimated values of $\\widehat{\\beta}_1$. What shape does the histogram take? What is the central value? What is the approximate spread of the distribution of values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE AND ANSWERS HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
